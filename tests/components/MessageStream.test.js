import { describe, it, expect, beforeEach, vi } from 'vitest';
import { render, cleanup } from '@testing-library/svelte';
import { get } from 'svelte/store';
import MessageStream from '../../src/ui/components/chat/MessageStream.svelte';
import { activeTabs } from '../../src/ui/stores/tabs.js';

/**
 * MessageStream Component Tests
 *
 * CRITICAL TEST PATTERN: "State Persistence Through Navigation"
 *
 * This tests the "round-trip" pattern:
 * 1. CREATE: Component mounts with data
 * 2. UNMOUNT: User navigates away (component unmounts)
 * 3. REMOUNT: User navigates back (component remounts)
 * 4. ASSERT: Data is still visible
 *
 * This catches the most common bug: "I only tested the happy path
 * where the component stays mounted"
 */

// Mock IPC for streaming chunks
const mockElectronAPI = {
  onLLMChunk: vi.fn(() => vi.fn()), // Returns unsubscribe function
};

// Setup global electronAPI
Object.defineProperty(window, 'electronAPI', {
  value: mockElectronAPI,
  writable: true,
  configurable: true,
});

describe('MessageStream - Conversation Persistence', () => {
  const testTabId = 'test-llm-tab-1';
  const testResponse = '# Test Response\n\nThis is a test conversation.\n\nIt has multiple paragraphs.';
  const testQuery = 'What is the meaning of life?';

  beforeEach(() => {
    // Clear all mocks
    vi.clearAllMocks();
    cleanup();

    // Reset tabs store
    activeTabs.set(new Map());
  });

  /**
   * THE MINIMAL TEST - This is what catches the bug!
   *
   * Pattern: Create â†’ Navigate Away â†’ Navigate Back â†’ Assert
   */
  describe('Round-Trip: Navigation Away and Back', () => {
    it('should display existing conversation after unmount/remount', () => {
      // STEP 1: CREATE - Set up tab with completed conversation
      const tab = {
        id: testTabId,
        title: 'LLM Response',
        url: `llm-response://123`,
        type: 'notes',
        component: 'llm-response',
        metadata: {
          isLLMResponse: true,
          query: testQuery,
          response: testResponse,  // â† Conversation already exists!
          isStreaming: false,       // â† Streaming is done
          tokensIn: 50,
          tokensOut: 100,
          model: 'claude-sonnet-4',
        },
      };

      activeTabs.update(tabs => {
        tabs.set(testTabId, tab);
        return tabs;
      });

      // STEP 2: MOUNT - Render the component (user navigates to conversation)
      const { getByText: getByText1, unmount } = render(MessageStream, {
        props: { tabId: testTabId },
      });

      // Verify conversation is visible initially
      expect(getByText1(testQuery)).toBeTruthy();
      expect(getByText1('Test Response')).toBeTruthy();

      // STEP 3: UNMOUNT - User navigates away
      unmount();

      // STEP 4: REMOUNT - User navigates back
      const { getByText: getByText2 } = render(MessageStream, {
        props: { tabId: testTabId },
      });

      // STEP 5: ASSERT - Conversation should STILL be visible
      // ðŸ› BUG: Current implementation fails here!
      expect(getByText2(testQuery)).toBeTruthy();
      expect(getByText2('Test Response')).toBeTruthy();
    });

    it('should preserve conversation when switching between tabs', () => {
      // Set up TWO conversation tabs
      const tab1 = {
        id: 'llm-1',
        title: 'First Conversation',
        url: 'llm-response://1',
        type: 'notes',
        component: 'llm-response',
        metadata: {
          isLLMResponse: true,
          query: 'First query',
          response: 'First response',
          isStreaming: false,
        },
      };

      const tab2 = {
        id: 'llm-2',
        title: 'Second Conversation',
        url: 'llm-response://2',
        type: 'notes',
        component: 'llm-response',
        metadata: {
          isLLMResponse: true,
          query: 'Second query',
          response: 'Second response',
          isStreaming: false,
        },
      };

      activeTabs.update(tabs => {
        tabs.set('llm-1', tab1);
        tabs.set('llm-2', tab2);
        return tabs;
      });

      // Render first tab
      const { getByText: getText1, unmount: unmount1 } = render(MessageStream, {
        props: { tabId: 'llm-1' },
      });

      expect(getText1('First query')).toBeTruthy();
      expect(getText1('First response')).toBeTruthy();

      // Switch to second tab
      unmount1();
      const { getByText: getText2, unmount: unmount2 } = render(MessageStream, {
        props: { tabId: 'llm-2' },
      });

      expect(getText2('Second query')).toBeTruthy();
      expect(getText2('Second response')).toBeTruthy();

      // Switch back to first tab
      unmount2();
      const { getByText: getText3 } = render(MessageStream, {
        props: { tabId: 'llm-1' },
      });

      // ðŸ› BUG: First conversation should still be there!
      expect(getText3('First query')).toBeTruthy();
      expect(getText3('First response')).toBeTruthy();
    });
  });

  /**
   * Supporting tests - These test other aspects but don't catch the main bug
   */
  describe('Initial Rendering', () => {
    it('should display query and metadata from tab', () => {
      const tab = {
        id: testTabId,
        title: 'LLM Response',
        url: 'llm-response://123',
        type: 'notes',
        component: 'llm-response',
        metadata: {
          isLLMResponse: true,
          query: testQuery,
          response: testResponse,
          isStreaming: false,
          tokensIn: 50,
          tokensOut: 100,
          model: 'claude-sonnet-4',
        },
      };

      activeTabs.set(new Map([[testTabId, tab]]));

      const { getByText } = render(MessageStream, {
        props: { tabId: testTabId },
      });

      // Should show query
      expect(getByText(testQuery)).toBeTruthy();

      // Should show metadata with specific labels
      expect(getByText(/claude-sonnet-4/i)).toBeTruthy();

      // Use function matchers to find text split across elements (with space)
      expect(getByText((content, element) => {
        return element?.textContent === 'Tokens In: 50';
      })).toBeTruthy();

      expect(getByText((content, element) => {
        return element?.textContent === 'Tokens Out: 100';
      })).toBeTruthy();

      expect(getByText((content, element) => {
        return element?.textContent === 'Total: 150';
      })).toBeTruthy();
    });
  });

  describe('Streaming', () => {
    it('should append new chunks while streaming', () => {
      const tab = {
        id: testTabId,
        title: 'LLM Response',
        url: 'llm-response://123',
        type: 'notes',
        component: 'llm-response',
        metadata: {
          isLLMResponse: true,
          query: testQuery,
          isStreaming: true,
        },
      };

      activeTabs.set(new Map([[testTabId, tab]]));

      let chunkCallback;
      mockElectronAPI.onLLMChunk.mockImplementation((callback) => {
        chunkCallback = callback;
        return vi.fn(); // unsubscribe
      });

      const { getByText } = render(MessageStream, {
        props: { tabId: testTabId },
      });

      // Simulate streaming chunks
      chunkCallback({ tabId: testTabId, chunk: 'Hello ' });
      chunkCallback({ tabId: testTabId, chunk: 'World!' });

      // Note: This test may need async/waitFor due to requestAnimationFrame
      // but demonstrates the streaming pattern
    });
  });
});

# Content Normalization UI Experiment

**Status:** ğŸ§ª Experimental
**Purpose:** Iterate on content normalization pipelines before integrating into main app

---

## Overview

This is a standalone experiment for testing and iterating on the content normalization UI. It runs separately from the main Electron browser, allowing rapid iteration on:

- **Pipeline visualization**: See artifacts flow through Capture â†’ Render â†’ Extract stages
- **Format conversions**: Test PDFâ†’Image, Imageâ†’Text, Webpageâ†’PDF pipelines
- **LLM extraction**: Use remote LLMs to extract/describe content from images and PDFs
- **Selection UX**: Experiment with how users select context for model queries

## Quick Start

```bash
# From the experiments/content-normalization-ui directory
npm install
npm run dev

# Opens at http://localhost:5174
```

## Architecture

```
experiments/content-normalization-ui/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ package.json           # Standalone dependencies
â”œâ”€â”€ vite.config.ts         # Vite configuration
â”œâ”€â”€ index.html             # Entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts            # App initialization
â”‚   â”œâ”€â”€ App.svelte         # Main layout
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ types.ts       # Re-exports from main app types
â”‚   â”‚   â”œâ”€â”€ mock-data.ts   # Sample pipelines for testing
â”‚   â”‚   â”œâ”€â”€ converters/    # Format conversion utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf-to-image.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ image-to-text.ts
â”‚   â”‚   â”‚   â””â”€â”€ llm-extract.ts
â”‚   â”‚   â””â”€â”€ stores/        # Experiment-specific stores
â”‚   â”‚       â””â”€â”€ experiment.ts
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ SourceUploader.svelte    # Upload PDFs, images, paste URLs
â”‚   â”‚   â”œâ”€â”€ PipelineView.svelte      # Main pipeline visualization
â”‚   â”‚   â”œâ”€â”€ StagePanel.svelte        # Individual stage artifacts
â”‚   â”‚   â”œâ”€â”€ ConversionPanel.svelte   # Run conversions
â”‚   â”‚   â”œâ”€â”€ LLMExtractPanel.svelte   # LLM-based extraction
â”‚   â”‚   â””â”€â”€ ContextPreview.svelte    # Preview what would go to model
â”‚   â””â”€â”€ samples/           # Sample files for testing
â”‚       â”œâ”€â”€ sample.pdf
â”‚       â””â”€â”€ sample-image.png
â””â”€â”€ tsconfig.json
```

## Features

### 1. Source Upload

Upload or paste content to create pipelines:
- **PDF files**: Drag & drop or file picker
- **Images**: PNG, JPEG, WebP support
- **URLs**: Paste webpage URLs (fetched via proxy or screenshot)
- **Text/Markdown**: Paste raw text content

### 2. Pipeline Visualization

See the full extraction pipeline:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CAPTURE   â”‚ â†’ â”‚   RENDER    â”‚ â†’ â”‚   EXTRACT   â”‚
â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
â”‚ Original    â”‚    â”‚ Normalized  â”‚    â”‚ Derived     â”‚
â”‚ content     â”‚    â”‚ visual      â”‚    â”‚ text        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each stage shows:
- Artifact previews (images, text snippets)
- Metadata (dimensions, token counts, quality)
- Provenance (what method produced this)
- Actions (regenerate, compare, select)

### 3. Format Conversions

Test different conversion paths:

| From | To | Method |
|------|-----|--------|
| PDF | Images | pdf.js rasterization |
| Webpage | PDF | Print to PDF |
| Webpage | Screenshot | Puppeteer/Playwright |
| Image | Text | Tesseract OCR |
| Image | Text | Vision LLM |
| PDF | Text | pdf.js text layer |

### 4. LLM Extraction

Use remote LLMs to extract content:

```typescript
// Example: Ask GPT-4o to describe a PDF page
const result = await llmExtract({
  image: pageImageBase64,
  prompt: "Extract all text from this document page. Preserve formatting.",
  model: "gpt-4o"
});
```

Supported providers:
- OpenAI (GPT-4o, GPT-4o-mini)
- Anthropic (Claude 3.5 Sonnet)
- Ollama (local models with vision)

### 5. Context Preview

See exactly what would be sent to the model:
- Text chunks with anchors
- Image attachments with dimensions
- Token count estimates
- Format toggle (rendered vs raw)

## Conversion Capabilities

### Local (No API Required)

1. **PDF â†’ Images**
   - Uses pdf.js for client-side rendering
   - Configurable DPI (72, 150, 300)
   - PNG or JPEG output

2. **PDF â†’ Text**
   - pdf.js text layer extraction
   - Preserves page structure
   - Quality hints based on text density

3. **Image â†’ Text (OCR)**
   - Tesseract.js for client-side OCR
   - Language detection
   - Confidence scores

### Remote (Requires API Key)

1. **Image â†’ Text (Vision LLM)**
   - Send image to vision model
   - Custom extraction prompts
   - Structured output support

2. **Webpage â†’ Description**
   - Screenshot page
   - Ask LLM to describe/summarize
   - Extract specific elements

3. **PDF â†’ Summary**
   - Render pages as images
   - Chain LLM calls for multi-page docs
   - Synthesize overall summary

## Configuration

Create `.env` in the experiment directory:

```env
# Optional: For LLM extraction features
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
OLLAMA_BASE_URL=http://localhost:11434
```

## Development

### Adding a New Converter

```typescript
// src/lib/converters/my-converter.ts
import type { CaptureArtifact, ExtractArtifact } from '../types';

export interface MyConverterOptions {
  // ...
}

export async function myConvert(
  input: CaptureArtifact,
  options: MyConverterOptions
): Promise<ExtractArtifact> {
  // Implementation
}
```

### Adding Sample Data

Add test files to `src/samples/` and register in `src/lib/mock-data.ts`:

```typescript
export const SAMPLE_SOURCES = [
  {
    name: 'My Sample PDF',
    type: 'pdf',
    path: '/samples/my-sample.pdf'
  }
];
```

## Testing Scenarios

### Scenario 1: PDF Document Pipeline

1. Upload a PDF
2. See capture artifact (original bytes)
3. Click "Render Pages" â†’ see rasterized images
4. Click "Extract Text" â†’ compare text layer vs OCR vs LLM
5. Select best extraction for context

### Scenario 2: Webpage Capture

1. Paste URL
2. Choose capture method (screenshot vs DOM)
3. Compare extraction methods (Readability vs DOM walker vs LLM)
4. Preview context output

### Scenario 3: Mixed Source Context

1. Upload PDF + paste URL + add note
2. See all three pipelines
3. Select artifacts from each
4. Preview combined context
5. Estimate total tokens

## Relationship to Main App

This experiment uses types from the main app:
- `src/types/pipeline.ts` â†’ Pipeline types
- `src/types/context-ir.ts` â†’ Context IR types

Successful patterns from this experiment will be integrated into:
- `src/main/services/pipeline/` â†’ Backend services
- `src/ui/components/artifacts/` â†’ UI components
- `src/ui/stores/pipeline.ts` â†’ State management

## Known Limitations

- No Electron APIs (runs in browser only)
- PDF rendering uses pdf.js (not native)
- Webpage capture requires CORS-friendly URLs or proxy
- File system access limited to uploads

## Next Steps

After experimentation:
1. Port successful UX patterns to main app
2. Integrate with Electron for native capabilities
3. Wire up IPC handlers
4. Add to tab context menu
